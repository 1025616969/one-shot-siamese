{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "from tqdm import trange\n",
    "\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../datasets/omniglot/'\n",
    "train_dir = data_dir + 'background/'\n",
    "test_dir = data_dir + 'evaluation/'\n",
    "processed = data_dir + 'processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensuring reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data\n",
    "\n",
    "The train data consists of 40 alphabets and 12 drawers.\n",
    "\n",
    "In each alphabet folder, there is 1 folder for each character in the alphabet. In each character folder, there are 20 images of this character drawn by each of the 20 drawers.\n",
    "\n",
    "- To create a pair belonging to the same class, we need to select 2 drawers from the same character dir, for any character dir inside the permitted language dirs.\n",
    "- To create a pair belonging to different classes, we need to select 2 drawers from different character dirs, for character dir inside the permitted language dirs.\n",
    "\n",
    "Ok so I'm gonna have a counter that starts from 0 and increments up to 30k. At each iteration, if the iteration number is even, I sample a like pair. If it is odd, I sample a dissimilar pair. \n",
    "\n",
    "- To sample a like pair, first I randomly select an alphabet from the list of training alphabets (uniform proba). Then, I randomly select a character from the list of characters in this alphabet (uniform proba). Then, I randomly select 2 drawers from the list of training drawers (uniform sampling) and select their corresponding image from the subdirectory.\n",
    "- To sample a dissimilar pair, I can do 2 things. The first method is to uniformally sample 1 alphabet, then uniformally sample 2 characters in the alphabet, uniformally sample 1 drawer (or 2) and index 1 drawer per alphabet to obtain 2 different characters from the same alphabet. The second method is to uniformally sample 2 alphabets, uniformally sample a character in each alphabet, uniformally sample a drawer per alphabet (or the same drawer), and obtain 2 different characters from 2 different alphabets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 40 alphabets.\n"
     ]
    }
   ],
   "source": [
    "# get list of alphabets\n",
    "original_alphabets = [os.path.join(train_dir, x) for x in next(os.walk(train_dir))[1]]\n",
    "\n",
    "# total number of drawers\n",
    "original_drawers = np.arange(1, 21)\n",
    "\n",
    "print(\"There are {} alphabets.\".format(len(original_alphabets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from 40 alphabets, randomly select 30\n",
    "train_alphabets = np.random.choice(original_alphabets, size=30, replace=False)\n",
    "remaining_alphabets = [x for x in original_alphabets if x not in train_alphabets]\n",
    "\n",
    "# from 20 drawers, randomly select 12\n",
    "train_drawers = np.random.choice(np.arange(20), size=12, replace=False)\n",
    "remaining_drawers = [x for x in original_drawers if x not in train_drawers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = int(30e3 / 2)\n",
    "cnt = True\n",
    "\n",
    "img_pairs = []\n",
    "label_pairs = []\n",
    "for i in trange(num_iters):\n",
    "    # sample a like pair\n",
    "    if i % 2 == 0:\n",
    "        # uniformly select 1 alphabet\n",
    "        alph = np.random.choice(train_alphabets)\n",
    "                \n",
    "        # uniformly sample 1 character\n",
    "        chars = [os.path.join(alph, x) for x in next(os.walk(alph))[1]]\n",
    "        char = np.random.choice(chars)\n",
    "                \n",
    "        # uniformly sample 2 drawers\n",
    "        ds = np.random.choice(train_drawers, size=2, replace=False)\n",
    "                \n",
    "        # get list of filenames to read in char dir\n",
    "        filenames = [\n",
    "            os.path.join(char, x) for x in next(os.walk(char))[-1] if int(\n",
    "                x.split(\"_\")[1][0:2].lstrip(\"0\")\n",
    "            ) in ds\n",
    "        ]\n",
    "        \n",
    "        # load pair as numpy array and store\n",
    "        pair = []\n",
    "        for name in filenames:\n",
    "            img_arr = img2array(name, gray=True, expand=True)\n",
    "            pair.append(img_arr)        \n",
    "        img_pairs.append(np.concatenate(pair, axis=0))\n",
    "        \n",
    "        # store ground truth lbl\n",
    "        gd_truth = np.array([1], dtype=np.int8)\n",
    "        label_pairs.append(gd_truth)\n",
    "        \n",
    "    # sample a dissimilar pair\n",
    "    else:\n",
    "        if cnt:\n",
    "            cnt = False\n",
    "\n",
    "            # uniformly select 1 alphabet\n",
    "            alph = np.random.choice(train_alphabets)\n",
    "\n",
    "             # uniformly sample 2 characters\n",
    "            chars = [os.path.join(alph, x) for x in next(os.walk(alph))[1]]\n",
    "            chars = np.random.choice(chars, size=2, replace=False)\n",
    "\n",
    "            # uniformly sample 1 drawer\n",
    "            d = np.random.choice(train_drawers)\n",
    "\n",
    "            filenames = []\n",
    "            for c in chars:\n",
    "                # get list of filenames to read in char dir\n",
    "                name = [\n",
    "                    os.path.join(c, x) for x in next(os.walk(c))[-1] if int(\n",
    "                        x.split(\"_\")[1][0:2].lstrip(\"0\")\n",
    "                    ) == d\n",
    "                ]\n",
    "                filenames.append(*name)\n",
    "            \n",
    "            # load pair as numpy array and store\n",
    "            pair = []\n",
    "            for name in filenames:\n",
    "                img_arr = img2array(name, gray=True, expand=True)\n",
    "                pair.append(img_arr)        \n",
    "            img_pairs.append(np.concatenate(pair, axis=0))\n",
    "            \n",
    "             # store ground truth lbl\n",
    "            gd_truth = np.array([0], dtype=np.int8)\n",
    "            label_pairs.append(gd_truth)\n",
    "        else:\n",
    "            cnt = True\n",
    "            \n",
    "            # uniformly select 2 alphabets\n",
    "            alph = np.random.choice(train_alphabets, size=2, replace=False)\n",
    "            \n",
    "            # uniformly sample 1 drawer\n",
    "            d = np.random.choice(train_drawers)\n",
    "            \n",
    "            filenames = []\n",
    "            for a in alph:\n",
    "                # uniformly sample 1 character\n",
    "                chars = [os.path.join(a, x) for x in next(os.walk(a))[1]]\n",
    "                char = np.random.choice(chars)\n",
    "\n",
    "                # get list of filenames to read in char dir\n",
    "                name = [\n",
    "                    os.path.join(char, x) for x in next(os.walk(char))[-1] if int(\n",
    "                        x.split(\"_\")[1][0:2].lstrip(\"0\")\n",
    "                    ) == d\n",
    "                ]\n",
    "                filenames.append(*name)\n",
    "\n",
    "            # load pair as numpy array and store\n",
    "            pair = []\n",
    "            for name in filenames:\n",
    "                img_arr = img2array(name, gray=True, expand=True)\n",
    "                pair.append(img_arr)        \n",
    "            img_pairs.append(np.concatenate(pair, axis=0))\n",
    "            \n",
    "             # store ground truth lbl\n",
    "            gd_truth = np.array([0], dtype=np.int8)\n",
    "            label_pairs.append(gd_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(img_pairs, open(processed + 'X_train.p', \"wb\"))\n",
    "pickle.dump(label_pairs, open(processed + 'y_train.p', \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Data\n",
    "\n",
    "The validation data consists of 10 alphabets and 4 drawers.\n",
    "\n",
    "The authors used 2 types of validation strategies for early-stopping of the model training. One of the method consists in creating a validation one-shot scenario to test the model's ability to generalize. We pick an alphabet from among the 10 available, choose 16 characters uniformly at random and select 2 of the 4 available drawers. We then select all the 16 characters produced by the first drawer, and individually compare against all 16 characters from the second drawer, with the goal of predicting the class of the character from among all of the second drawer's characters.\n",
    "\n",
    "This process is repeated twice for all alphabets (the second time we pick the 2 other drawers), so that there are 32 one-shot learning trials for each of the 10 validation alphabets, for a total of 320 one-shot trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the 40 alphabets, select the last 10\n",
    "valid_alphabets = remaining_alphabets\n",
    "\n",
    "# from remaining 8 drawers, select 4\n",
    "valid_drawers = np.random.choice(remaining_drawers, size=4, replace=False)\n",
    "remaining_drawers = [x for x in remaining_drawers if x not in valid_drawers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = len(valid_alphabets)\n",
    "pop = 10\n",
    "\n",
    "valid_img_pairs = []\n",
    "valid_label_pairs = []\n",
    "for alph in valid_alphabets:\n",
    "    drawer_pair_imgs = []\n",
    "    drawer_pair_gd_truth = []\n",
    "    for j in range(2):\n",
    "        # grab drawers\n",
    "        ds = [valid_drawers[2*j], valid_drawers[2*j + 1]]\n",
    "        \n",
    "        # sample first 16 characters (since some might not be available)\n",
    "        chars = [os.path.join(alph, x) for x in next(os.walk(alph))[1]]\n",
    "        chars = np.random.choice(chars, size=pop, replace=False)\n",
    "        \n",
    "        # grab filenames for both drawers\n",
    "        filenames = []\n",
    "        for d in ds:\n",
    "            for char in chars:\n",
    "                names = [\n",
    "                    os.path.join(char, x) for x in next(os.walk(char))[-1] if int(\n",
    "                        x.split(\"_\")[1][0:2].lstrip(\"0\")\n",
    "                    ) == d\n",
    "                ]\n",
    "                filenames.append(*names)\n",
    "        d1 = filenames[:pop]\n",
    "        d2 = filenames[pop:]\n",
    "        \n",
    "        img_trial = []\n",
    "        gd_truth = []\n",
    "        for i, left in enumerate(d1):\n",
    "            img_pairs = []\n",
    "            for right in d2:\n",
    "                im_names = [left, right]\n",
    "                pair = []\n",
    "                for name in im_names:\n",
    "                    img_arr = img2array(name, gray=True, expand=True)\n",
    "                    pair.append(img_arr) \n",
    "                pair = np.concatenate(pair, axis=0)\n",
    "                img_pairs.append(pair)\n",
    "            img_trial.append(img_pairs)\n",
    "            label = np.array([i], dtype=np.int8)\n",
    "            gd_truth.append(label)\n",
    "            \n",
    "        drawer_pair_imgs.extend(img_trial)\n",
    "        drawer_pair_gd_truth.extend(gd_truth)\n",
    "\n",
    "    valid_img_pairs.extend(drawer_pair_imgs)\n",
    "    valid_label_pairs.extend(drawer_pair_gd_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(valid_img_pairs, open(processed + 'X_valid.p', \"wb\"))\n",
    "pickle.dump(valid_label_pairs, open(processed + 'y_valid.p', \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
