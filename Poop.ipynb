{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import *\n",
    "from tqdm import trange\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/processed/'\n",
    "train_dir = data_dir + 'background/'\n",
    "test_dir = data_dir + 'evaluation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensuring reproducibility\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Validation\n",
    "\n",
    "Extracted from background folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 background alphabets.\n"
     ]
    }
   ],
   "source": [
    "# get list of alphabets\n",
    "background_alphabets = [x for x in next(os.walk(train_dir))[1]]\n",
    "background_alphabets.sort()\n",
    "\n",
    "print(\"There are {} background alphabets.\".format(len(background_alphabets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80-20 train-valid split\n",
    "valid_size = 0.2\n",
    "num_alphabets = len(background_alphabets)\n",
    "\n",
    "indices = list(range(num_alphabets))\n",
    "split = int(np.floor(valid_size * num_alphabets))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "train_alphabets = [background_alphabets[idx] for idx in train_idx]\n",
    "valid_alphabets = [background_alphabets[idx] for idx in valid_idx]\n",
    "\n",
    "train_alphabets.sort()\n",
    "valid_alphabets.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_alphabets = {}\n",
    "for alph in train_alphabets:\n",
    "    # get sorted list of characters in alphabet\n",
    "    alph_path = os.path.join(train_dir, alph)\n",
    "    characters = os.listdir(alph_path)\n",
    "    characters.sort()\n",
    "    \n",
    "    # store image names in each character\n",
    "    alphabet = {}\n",
    "    for char in characters:\n",
    "        # get sorted list of images in character\n",
    "        char_path = os.path.join(alph_path, char)\n",
    "        imgs = os.listdir(char_path)\n",
    "        imgs.sort()\n",
    "\n",
    "        alphabet[char] = imgs\n",
    "    all_train_alphabets[alph] = alphabet\n",
    "    \n",
    "all_valid_alphabets = {}\n",
    "for alph in valid_alphabets:\n",
    "    # get sorted list of characters in alphabet\n",
    "    alph_path = os.path.join(train_dir, alph)\n",
    "    characters = os.listdir(alph_path)\n",
    "    characters.sort()\n",
    "    \n",
    "    alphabet = {}\n",
    "    for char in characters:\n",
    "        # get sorted list of images in character\n",
    "        char_path = os.path.join(alph_path, char)\n",
    "        imgs = os.listdir(char_path)\n",
    "        imgs.sort()\n",
    "\n",
    "        alphabet[char] = imgs\n",
    "    all_valid_alphabets[alph] = alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test\n",
    "\n",
    "Extracted from evaluation folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20 evaluation alphabets.\n"
     ]
    }
   ],
   "source": [
    "# get list of alphabets\n",
    "evaluation_alphabets = [x for x in next(os.walk(test_dir))[1]]\n",
    "evaluation_alphabets.sort()\n",
    "\n",
    "print(\"There are {} evaluation alphabets.\".format(len(evaluation_alphabets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_evaluation_alphabets = {}\n",
    "for alph in evaluation_alphabets:\n",
    "    # get sorted list of characters in alphabet\n",
    "    alph_path = os.path.join(test_dir, alph)\n",
    "    characters = os.listdir(alph_path)\n",
    "    characters.sort()\n",
    "    \n",
    "    alphabet = {}\n",
    "    for char in characters:\n",
    "        # get sorted list of images in character\n",
    "        char_path = os.path.join(alph_path, char)\n",
    "        imgs = os.listdir(char_path)\n",
    "        imgs.sort()\n",
    "\n",
    "        alphabet[char] = imgs\n",
    "    all_evaluation_alphabets[alph] = alphabet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load A Batch of N Train Pairs\n",
    "\n",
    "The goal is to provide a batch of size n, with n/2 like pairs, and n/2 dissimilar pairs. Each batch will only contain instances from a single alphabet.\n",
    "\n",
    "To get `n/2` dissimilar pairs, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_alphabets.keys())\n",
    "sampling_indices = np.arange(num_train)\n",
    "np.random.shuffle(sampling_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OmniglotLoader:\n",
    "    \"\"\"Class that loads and prepares the Omniglot dataset\n",
    "    This Class was constructed to read the Omniglot alphabets, separate the \n",
    "    training, validation and evaluation test. It also provides function for\n",
    "    geting one-shot task batches.\n",
    "    Attributes:\n",
    "        dataset_path: path of Omniglot Dataset\n",
    "        train_dictionary: dictionary of the files of the train set (background set). \n",
    "            This dictionary is used to load the batch for training and validation.\n",
    "        evaluation_dictionary: dictionary of the evaluation set. \n",
    "        image_width: self explanatory\n",
    "        image_height: self explanatory\n",
    "        batch_size: size of the batch to be used in training\n",
    "        use_augmentation: boolean that allows us to select if data augmentation is \n",
    "            used or not\n",
    "        image_augmentor: instance of class ImageAugmentor that augments the images\n",
    "            with the affine transformations referred in the paper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_path, batch_size):\n",
    "        \"\"\"Inits OmniglotLoader with the provided values for the attributes.\n",
    "        It also creates an Image Augmentor object and loads the train set and \n",
    "        evaluation set into dictionaries for future batch loading.\n",
    "        Arguments:\n",
    "            dataset_path: path of Omniglot dataset\n",
    "            use_augmentation: boolean that allows us to select if data augmentation \n",
    "                is used or not       \n",
    "            batch_size: size of the batch to be used in training     \n",
    "        \"\"\"\n",
    "\n",
    "        self.dataset_path = dataset_path\n",
    "        self.train_dictionary = {}\n",
    "        self.evaluation_dictionary = {}\n",
    "        self.image_width = 105\n",
    "        self.image_height = 105\n",
    "        self.batch_size = batch_size\n",
    "        self.__train_alphabets = []\n",
    "        self.__validation_alphabets = []\n",
    "        self.__evaluation_alphabets = []\n",
    "        self.__current_train_alphabet_index = 0\n",
    "        self.__current_validation_alphabet_index = 0\n",
    "        self.__current_evaluation_alphabet_index = 0\n",
    "\n",
    "        self.load_dataset()\n",
    "\n",
    "        self.use_augmentation = []\n",
    "\n",
    "    def load_dataset(self):\n",
    "        \"\"\"Loads the alphabets into dictionaries\n",
    "        Loads the Omniglot dataset and stores the available images for each\n",
    "        alphabet for each of the train and evaluation set.\n",
    "        \"\"\"\n",
    "\n",
    "        train_path = os.path.join(self.dataset_path, 'background')\n",
    "        validation_path = os.path.join(self.dataset_path, 'evaluation')\n",
    "\n",
    "        # First let's take care of the train alphabets\n",
    "        for alphabet in os.listdir(train_path):\n",
    "            alphabet_path = os.path.join(train_path, alphabet)\n",
    "\n",
    "            current_alphabet_dictionary = {}\n",
    "\n",
    "            for character in os.listdir(alphabet_path):\n",
    "                character_path = os.path.join(alphabet_path, character)\n",
    "\n",
    "                current_alphabet_dictionary[character] = os.listdir(\n",
    "                    character_path)\n",
    "\n",
    "            self.train_dictionary[alphabet] = current_alphabet_dictionary\n",
    "\n",
    "        # Now it's time for the validation alphabets\n",
    "        for alphabet in os.listdir(validation_path):\n",
    "            alphabet_path = os.path.join(validation_path, alphabet)\n",
    "\n",
    "            current_alphabet_dictionary = {}\n",
    "\n",
    "            for character in os.listdir(alphabet_path):\n",
    "                character_path = os.path.join(alphabet_path, character)\n",
    "\n",
    "                current_alphabet_dictionary[character] = os.listdir(\n",
    "                    character_path)\n",
    "\n",
    "            self.evaluation_dictionary[alphabet] = current_alphabet_dictionary\n",
    "\n",
    "    def split_train_datasets(self):\n",
    "        \"\"\" Splits the train set in train and validation\n",
    "        Divide the 30 train alphabets in train and validation with\n",
    "        # a 80% - 20% split (24 vs 6 alphabets)\n",
    "        \"\"\"\n",
    "\n",
    "        available_alphabets = list(self.train_dictionary.keys())\n",
    "        number_of_alphabets = len(available_alphabets)\n",
    "\n",
    "        train_indexes = random.sample(\n",
    "            range(0, number_of_alphabets - 1), int(0.8 * number_of_alphabets))\n",
    "\n",
    "        # If we sort the indexes in reverse order we can pop them from the list\n",
    "        # and don't care because the indexes do not change\n",
    "        train_indexes.sort(reverse=True)\n",
    "\n",
    "        for index in train_indexes:\n",
    "            self.__train_alphabets.append(available_alphabets[index])\n",
    "            available_alphabets.pop(index)\n",
    "\n",
    "        # The remaining alphabets are saved for validation\n",
    "        self.__validation_alphabets = available_alphabets\n",
    "        self.__evaluation_alphabets = list(self.evaluation_dictionary.keys())\n",
    "\n",
    "    def __convert_path_list_to_images_and_labels(self, path_list, is_one_shot_task):\n",
    "        \"\"\" Loads the images and its correspondent labels from the path\n",
    "        Take the list with the path from the current batch, read the images and\n",
    "        return the pairs of images and the labels\n",
    "        If the batch is from train or validation the labels are alternately 1's and\n",
    "        0's. If it is a evaluation set only the first pair has label 1\n",
    "        Arguments:\n",
    "            path_list: list of images to be loaded in this batch\n",
    "            is_one_shot_task: flag sinalizing if the batch is for one-shot task or if\n",
    "                it is for training\n",
    "        Returns:\n",
    "            pairs_of_images: pairs of images for the current batch\n",
    "            labels: correspondent labels -1 for same class, 0 for different classes\n",
    "        \"\"\"\n",
    "        number_of_pairs = int(len(path_list) / 2)\n",
    "        pairs_of_images = [np.zeros(\n",
    "            (number_of_pairs, self.image_height, self.image_height, 1)) for i in range(2)]\n",
    "        labels = np.zeros((number_of_pairs, 1))\n",
    "\n",
    "        for pair in range(number_of_pairs):\n",
    "            image = Image.open(path_list[pair * 2])\n",
    "            image = np.asarray(image).astype(np.float64)\n",
    "            image = image / image.std() - image.mean()\n",
    "\n",
    "            pairs_of_images[0][pair, :, :, 0] = image\n",
    "            image = Image.open(path_list[pair * 2 + 1])\n",
    "            image = np.asarray(image).astype(np.float64)\n",
    "            image = image / image.std() - image.mean()\n",
    "\n",
    "            pairs_of_images[1][pair, :, :, 0] = image\n",
    "            if not is_one_shot_task:\n",
    "                if (pair + 1) % 2 == 0:\n",
    "                    labels[pair] = 0\n",
    "                else:\n",
    "                    labels[pair] = 1\n",
    "\n",
    "            else:\n",
    "                if pair == 0:\n",
    "                    labels[pair] = 1\n",
    "                else:\n",
    "                    labels[pair] = 0\n",
    "\n",
    "        if not is_one_shot_task:\n",
    "            random_permutation = np.random.permutation(number_of_pairs)\n",
    "            labels = labels[random_permutation]\n",
    "            pairs_of_images[0][:, :, :,\n",
    "                               :] = pairs_of_images[0][random_permutation, :, :, :]\n",
    "            pairs_of_images[1][:, :, :,\n",
    "                               :] = pairs_of_images[1][random_permutation, :, :, :]\n",
    "\n",
    "        return pairs_of_images, labels\n",
    "\n",
    "    def get_train_batch(self):\n",
    "        \"\"\" Loads and returns a batch of train images\n",
    "        Get a batch of pairs from the training set. Each batch will contain\n",
    "        images from a single alphabet. I decided to select one single example\n",
    "        from random n/2 characters in each alphabet. If the current alphabet\n",
    "        has lower number of characters than n/2 (some of them have 14) we\n",
    "        sample repeated classed for that batch per character in the alphabet\n",
    "        to pair with a different categories. In the other half of the batch\n",
    "        I selected pairs of same characters. In resume we will have a batch\n",
    "        size of n, with n/2 pairs of different classes and n/2 pairs of the same\n",
    "        class. Each batch will only contains samples from one single alphabet.\n",
    "        Returns:\n",
    "            pairs_of_images: pairs of images for the current batch\n",
    "            labels: correspondent labels -1 for same class, 0 for different classes\n",
    "        \"\"\"\n",
    "\n",
    "        current_alphabet = self.__train_alphabets[self.__current_train_alphabet_index]\n",
    "        available_characters = list(\n",
    "            self.train_dictionary[current_alphabet].keys())\n",
    "        number_of_characters = len(available_characters)\n",
    "\n",
    "        bacth_images_path = []\n",
    "\n",
    "        # If the number of classes if less than self.batch_size/2\n",
    "        # we have to repeat characters\n",
    "        selected_characters_indexes = [random.randint(\n",
    "            0, number_of_characters-1) for i in range(self.batch_size)]\n",
    "        \n",
    "        for index in selected_characters_indexes:\n",
    "            current_character = available_characters[index]\n",
    "            available_images = (self.train_dictionary[current_alphabet])[\n",
    "                current_character]\n",
    "            image_path = os.path.join(\n",
    "                self.dataset_path, 'background', current_alphabet, current_character)\n",
    "\n",
    "            # Random select a 3 indexes of images from the same character (Remember\n",
    "            # that for each character we have 20 examples).\n",
    "            image_indexes = random.sample(range(0, 19), 3)\n",
    "            image = os.path.join(\n",
    "                image_path, available_images[image_indexes[0]])\n",
    "            bacth_images_path.append(image)\n",
    "            image = os.path.join(\n",
    "                image_path, available_images[image_indexes[1]])\n",
    "            bacth_images_path.append(image)\n",
    "\n",
    "            # Now let's take care of the pair of images from different characters\n",
    "            image = os.path.join(\n",
    "                image_path, available_images[image_indexes[2]])\n",
    "            bacth_images_path.append(image)\n",
    "            different_characters = available_characters[:]\n",
    "            different_characters.pop(index)\n",
    "            different_character_index = random.sample(\n",
    "                range(0, number_of_characters - 1), 1)\n",
    "            current_character = different_characters[different_character_index[0]]\n",
    "            available_images = (self.train_dictionary[current_alphabet])[\n",
    "                current_character]\n",
    "            image_indexes = random.sample(range(0, 20), 1)\n",
    "            image_path = os.path.join(\n",
    "                self.dataset_path, 'background', current_alphabet, current_character)\n",
    "            image = os.path.join(\n",
    "                image_path, available_images[image_indexes[0]])\n",
    "            bacth_images_path.append(image)\n",
    "\n",
    "        self.__current_train_alphabet_index += 1\n",
    "\n",
    "        if (self.__current_train_alphabet_index > 23):\n",
    "            self.__current_train_alphabet_index = 0\n",
    "\n",
    "        images, labels = self.__convert_path_list_to_images_and_labels(\n",
    "            bacth_images_path, is_one_shot_task=False)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def get_one_shot_batch(self, support_set_size, is_validation):\n",
    "        \"\"\" Loads and returns a batch for one-shot task images\n",
    "        Gets a one-shot batch for evaluation or validation set, it consists in a\n",
    "        single image that will be compared with a support set of images. It returns\n",
    "        the pair of images to be compared by the model and it's labels (the first\n",
    "        pair is always 1) and the remaining ones are 0's\n",
    "        Returns:\n",
    "            pairs_of_images: pairs of images for the current batch\n",
    "            labels: correspondent labels -1 for same class, 0 for different classes\n",
    "        \"\"\"\n",
    "\n",
    "        # Set some variables that will be different for validation and evaluation sets\n",
    "        if is_validation:\n",
    "            alphabets = self.__validation_alphabets\n",
    "            current_alphabet_index = self.__current_validation_alphabet_index\n",
    "            image_folder_name = 'images_background'\n",
    "            dictionary = self.train_dictionary\n",
    "        else:\n",
    "            alphabets = self.__evaluation_alphabets\n",
    "            current_alphabet_index = self.__current_evaluation_alphabet_index\n",
    "            image_folder_name = 'images_evaluation'\n",
    "            dictionary = self.evaluation_dictionary\n",
    "\n",
    "        current_alphabet = alphabets[current_alphabet_index]\n",
    "        available_characters = list(dictionary[current_alphabet].keys())\n",
    "        number_of_characters = len(available_characters)\n",
    "\n",
    "        bacth_images_path = []\n",
    "\n",
    "        test_character_index = random.sample(\n",
    "            range(0, number_of_characters), 1)\n",
    "\n",
    "        # Get test image\n",
    "        current_character = available_characters[test_character_index[0]]\n",
    "\n",
    "        available_images = (dictionary[current_alphabet])[current_character]\n",
    "\n",
    "        image_indexes = random.sample(range(0, 20), 2)\n",
    "        image_path = os.path.join(\n",
    "            self.dataset_path, image_folder_name, current_alphabet, current_character)\n",
    "\n",
    "        test_image = os.path.join(\n",
    "            image_path, available_images[image_indexes[0]])\n",
    "        bacth_images_path.append(test_image)\n",
    "        image = os.path.join(\n",
    "            image_path, available_images[image_indexes[1]])\n",
    "        bacth_images_path.append(image)\n",
    "\n",
    "        # Let's get our test image and a pair corresponding to\n",
    "        if support_set_size == -1:\n",
    "            number_of_support_characters = number_of_characters\n",
    "        else:\n",
    "            number_of_support_characters = support_set_size\n",
    "\n",
    "        different_characters = available_characters[:]\n",
    "        different_characters.pop(test_character_index[0])\n",
    "\n",
    "        # There may be some alphabets with less than 20 characters\n",
    "        if number_of_characters < number_of_support_characters:\n",
    "            number_of_support_characters = number_of_characters\n",
    "\n",
    "        support_characters_indexes = random.sample(\n",
    "            range(0, number_of_characters - 1), number_of_support_characters - 1)\n",
    "\n",
    "        for index in support_characters_indexes:\n",
    "            current_character = different_characters[index]\n",
    "            available_images = (dictionary[current_alphabet])[\n",
    "                current_character]\n",
    "            image_path = os.path.join(\n",
    "                self.dataset_path, image_folder_name, current_alphabet, current_character)\n",
    "\n",
    "            image_indexes = random.sample(range(0, 20), 1)\n",
    "            image = os.path.join(\n",
    "                image_path, available_images[image_indexes[0]])\n",
    "            bacth_images_path.append(test_image)\n",
    "            bacth_images_path.append(image)\n",
    "\n",
    "        images, labels = self.__convert_path_list_to_images_and_labels(\n",
    "            bacth_images_path, is_one_shot_task=True)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def one_shot_test(self, model, support_set_size, number_of_tasks_per_alphabet,\n",
    "                      is_validation):\n",
    "        \"\"\" Prepare one-shot task and evaluate its performance\n",
    "        Make one shot task in validation and evaluation sets\n",
    "        if support_set_size = -1 we perform a N-Way one-shot task with\n",
    "        N being the total of characters in the alphabet\n",
    "        Returns:\n",
    "            mean_accuracy: mean accuracy for the one-shot task\n",
    "        \"\"\"\n",
    "\n",
    "        # Set some variables that depend on dataset\n",
    "        if is_validation:\n",
    "            alphabets = self.__validation_alphabets\n",
    "            print('\\nMaking One Shot Task on validation alphabets:')\n",
    "        else:\n",
    "            alphabets = self.__evaluation_alphabets\n",
    "            print('\\nMaking One Shot Task on evaluation alphabets:')\n",
    "\n",
    "        mean_global_accuracy = 0\n",
    "\n",
    "        for alphabet in alphabets:\n",
    "            mean_alphabet_accuracy = 0\n",
    "            for _ in range(number_of_tasks_per_alphabet):\n",
    "                images, _ = self.get_one_shot_batch(\n",
    "                    support_set_size, is_validation=is_validation)\n",
    "                probabilities = model.predict_on_batch(images)\n",
    "\n",
    "                # Added this condition because noticed that sometimes the outputs\n",
    "                # of the classifier was almost the same in all images, meaning that\n",
    "                # the argmax would be always by defenition 0.\n",
    "                if np.argmax(probabilities) == 0 and probabilities.std()>0.01:\n",
    "                    accuracy = 1.0\n",
    "                else:\n",
    "                    accuracy = 0.0\n",
    "\n",
    "                mean_alphabet_accuracy += accuracy\n",
    "                mean_global_accuracy += accuracy\n",
    "\n",
    "            mean_alphabet_accuracy /= number_of_tasks_per_alphabet\n",
    "\n",
    "            print(alphabet + ' alphabet' + ', accuracy: ' +\n",
    "                  str(mean_alphabet_accuracy))\n",
    "            if is_validation:\n",
    "                self.__current_validation_alphabet_index += 1\n",
    "            else:\n",
    "                self.__current_evaluation_alphabet_index += 1\n",
    "\n",
    "        mean_global_accuracy /= (len(alphabets) *\n",
    "                                 number_of_tasks_per_alphabet)\n",
    "\n",
    "        print('\\nMean global accuracy: ' + str(mean_global_accuracy))\n",
    "\n",
    "        # reset counter\n",
    "        if is_validation:\n",
    "            self.__current_validation_alphabet_index = 0\n",
    "        else:\n",
    "            self.__current_evaluation_alphabet_index = 0\n",
    "\n",
    "        return mean_global_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = OmniglotLoader(data_dir, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.split_train_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = loader.get_train_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x[0]\n",
    "x2 = x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.arange(10)\n",
    "\n",
    "sample_x1 = x1[mask]\n",
    "sample_x2 = x2[mask]\n",
    "sample_y = y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "\n",
    "n = len(sample_x1)\n",
    "\n",
    "for i in range(n):\n",
    "    top = sample_x1[i]\n",
    "    bottom = sample_x2[i]\n",
    "\n",
    "    # display top\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(top.squeeze())\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display bottom\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(bottom.squeeze())\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
